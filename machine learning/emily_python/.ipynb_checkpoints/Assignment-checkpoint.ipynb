{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0. Ниже напишите Ваши ФИО и номер группы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Иванычев Сергей Дмитриевич, группа 376 (база с 374-й)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача Bike Sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача на kaggle: https://www.kaggle.com/c/bike-sharing-demand\n",
    "\n",
    "По историческим данным о прокате велосипедов и погодных условиях необходимо спрогнозировтаь спрос на прокат велосипедов.\n",
    "\n",
    "В исходной псотановке задачи доступно 9 признаков: https://www.kaggle.com/c/prudential-life-insurance-assessment/data\n",
    "\n",
    "В наборе признаков присутсвуют вещественные, категориальные, и бинарные данные. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ и визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, ensemble, grid_search, linear_model, metrics, pipeline, preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Считайте данные из файла bike_sharing_train.csv в pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-81c8d87f9a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bike_sharing_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"bike_sharing_train.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Выведите небольшую часть получившегося DataFrame на экран, посмотрите на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 . Проанализируйте описание данных:\n",
    "\n",
    "***datetime*** - hourly date + timestamp  \n",
    "\n",
    "***season*** -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n",
    "\n",
    "***holiday*** - whether the day is considered a holiday\n",
    "\n",
    "***workingday*** - whether the day is neither a weekend nor holiday\n",
    "\n",
    "***weather*** - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "    \n",
    "***temp*** - temperature in Celsius\n",
    "\n",
    "***atemp*** - \"feels like\" temperature in Celsius\n",
    "\n",
    "***humidity*** - relative humidity\n",
    "\n",
    "***windspeed*** - wind speed\n",
    "\n",
    "***count*** - number of total rentals"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. По описанию данных предположите, какие признаки окажут наибольший вклад в модель?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Предположите, какие признаки окажутся наименее полезными?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. В наборе данных доступны вещественные, бинарные и категориальные признаки, однако со всеми из них можно работать как с вещественными. Давайте посмотрим на графиках, как целевой признак зависит от остальных. \n",
    "Постройте графики, на которых отробразите объекты в пространстве пар целевая функция/признак для всех признаков.\n",
    "Для наглядности используйте pylab.subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Какие выводы Вы можете сделать по графикам? Например, в каком году прокат велосипедов пользовался большим спросом? В какие дни, рабочие или выходные, прокат пользуется большим спросом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Давайте более строго оценим уровень линейной зависимости между признаками и целевой переменной. Хорошей мерой линейной зависимости между двумя векторами является корреляция Пирсона. В pandas ее можно посчитать с помощью двух методов dataFrame: corr и corrwith. Метод dataFrame.corr вычисляет матрицу корреляций всех признаков из dataFrame. Методу df.corrwith нужно подать еще один dataFrame в качестве аргумента, и тогда он посчитает попарные корреляции между признаками из исходного dataFrame и переданного dataFrame.\n",
    "\n",
    "8. Посчитайте корреляции всех признаков с целевой функцией с помощью метода corrwith. Есть ли в выборке признаки, коррелирующие с целевой функцией?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Посчитайте попарные корреляции между парами признаков с помощью метода corr. Есть ли в выборке признаки, сильно коррелирующие между собой? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Посчитайте средние значения и отклонения для признаков. Отличается ли масштаб признаков? К чему это может привести?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейные модели"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Разделите данные на обучающую и тестовую выборки. Данные имеют временную приявязку, поэтому их нужно разделить по времени: в тестовую выборку нужно выделить объекты из более позднего временного промежутка, по сравнению с обучающей выборкой. РАзмер тестовой выборки выеберите самостоятельно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2.  В наборе данных доступны вещественные, бинарные и категориальные признаки, однако со всеми из них можно работать как с вещественными признаками, давайте будем делать именно так. Согласно пункту 10 из раздела \"Анализ и визуализация данных\" признаки имеют разный маштаб. Отбмасштабируйте признаки с помощью преобразования preprocessing.StandardScaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3.1 Обучите модели linear_model.SGDRegressor и linear_model.Lasso. Оцените качество модели с помощью метрики MAE (metrics.mean_absolute_error). Сравните качество на обучении и на тесте. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3.2 Проанализируйте веса регрессии. Какие выводы можно сделать? Какие признаки внесли наибольший вклад в модель?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Придумайте и сгенерируйте несколько дополнительных признаков на основе существующего набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Обучите одну из моделей linear_model.SGDRegressor или linear_model.Lasso на получившемся наборе признаков, не забыв предварительно их отмасштабировать. Изменилось ли качество классификации? С какими весами Ваши признаки вошли в модель? Можно ли сделать вывод о том, что от добавления новых признаков качество модели улучшилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Теперь давайте по-разному обработаем признаки разного типа. Для того, чтобы удобно работать с набором преобразований данных будем использовать pipeline.Pipeline. Ознакомьтесь с примером ниже: а рамках примера строится piplene из двух шагов: обработка данных и обучение модели. В рамках первого шага сначала обрабатываются бинарные данные (остаются без изменений), а потом -  вещественные признаки (масштабируются). На втором шаге строится модель регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Пример:\n",
    "# train_data, train_labels - DataFrame с обучающей выборкой и значения целевой функции на обучении\n",
    "# test_data, test_labels - DataFrame с тестовой выборкой и значения целевой функции на тесте\n",
    "\n",
    "# Создание индекса для бинарных признаков\n",
    "binary_data_columns = ['holiday', 'workingday']\n",
    "binary_data_indices = np.array([(column in binary_data_columns) for column in train_data.columns], dtype = bool)\n",
    "\n",
    "# Создание индекса для вещественных признаков\n",
    "numeric_data_columns = ['temp', 'atemp', 'humidity', 'windspeed', 'season', 'weather']\n",
    "numeric_data_indices = np.array([(column in numeric_data_columns) for column in train_data.columns], dtype = bool)\n",
    "\n",
    "# Создание модели регресии\n",
    "model = linear_model.SGDRegressor(random_state = 0)\n",
    "\n",
    "# Объявление pipline -  цепочки преобразования данных, начиная от обработки данных в зависимости от их типа, и \n",
    "# заканчивая обучением модели. \n",
    "\n",
    "estimator = pipeline.Pipeline(steps = [       \n",
    "    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "            #binary\n",
    "            ('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "                    \n",
    "            #numeric\n",
    "            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "                ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices])),\n",
    "                ('scaling', preprocessing.StandardScaler())            \n",
    "                        ])),\n",
    "\n",
    "        ])),\n",
    "    ('model_fitting', model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# С цепочкой можно работать как с одиночным преобразованием, в частности вызывать методы fit и predict \n",
    "estimator.fit(train_data, train_labels)\n",
    "metrics.mean_absolute_error(test_labels, estimator.predict(test_data))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. На основе примера выше постройте pipeline, который обрабатывает 3 типа признаков: бинарные, вещественные (делаем масштабирование) и категориальные (обрабатываем данные с помощью метода One Hot Encoding - preprocessing.OneHotEncoder). Обучите получившуюся цепочку и оцените качество. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Сделайте выводы: как обработка признаков повлияла на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Продолжаем работать с pipeline. Подбрети параметры модели с помощью случайного поиска по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Сделайте выводы: как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "11. Постройте следующий график: отобразите объекты тестовой и обучающей выборок (объекты из обучения и теста должны отображаться разными цветами) в координатах целевая функция/оценка целевой функции с помощью псостроенной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "12. Какие выводы можно сделать на основе построенного графика? Насколько хорошую модель мы получили?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Обучите модель случайный лес (ensemble.RandomForestRegressor) и оцените качество получившейся модели на обучении и на тесте. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Проанализируйте важность признаков с помощью метода feature_importances_. Какие признаки оказали наибольший вклад в модель? Соответсвует ли это Вашим предположениям о вкладе признаков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Постройте следующий график: отобразите объекты тестовой и обучающей выборок (объекты из обучения и теста должны отображаться разными цветами) в координатах целевая функция/оценка целевой функции с помощью псостроенной модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Сравните график, полученный на предыдущем шаге с соответсвующим графиком для линейной модели. Какие выводы можно сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Опциональная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте улучшить результат, полученный на предыдущих шагах. В этом разделе можно и нужно пользоваться любыми изученными алгоритмами, инструментами и всем, чем вам захочется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе Вы можете написать, какие выводы Вы сделали в процессе работы над заданием, понравилось ли оно Вам, а также всё, что Вы о задании думаете =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
